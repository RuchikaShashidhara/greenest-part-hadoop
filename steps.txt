-> Install Hadoop using the guide here.

You will have 2 users ubuntu and hadoopusr

Login into ubuntu using your password.

Install opencv using the command sudo apt install python3-opencv 
Install numpy using pip3 install numpy 

Place the mapper.txt and reducer.txt files in /home/ubuntu
Place the data.txt file in /home/ubuntu/data

Open Terminal in user - ubuntu

Use  the following command to login to the other user and then ssh into localhost
su - hadoopusr
ssh localhost

To start all nodes:
start-all.sh
Tocheck whether all nodes are up:
jps - 6 nodes should be up.

To make a folder in dfs on hadoop:
hadoop dfs -mkdir /data 

To put data.txt from local system to hadoop file system 
hadoop fs -put /home/ubuntu/data /data 


To confirm whether its done or not:
hadoop dfs -ls /data/data

To run the task:
hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar -file /home/ubuntu/mapper.py -mapper /home/ubuntu/mapper.py -file /home/ubuntu/reducer.py -reducer /home/ubuntu/reducer.py -input /data/* -output /data-output

Visit localhost:50070/explorer.html to view the job result
Click on data-output and click on part-00000

Now download this file.
This will ontain the result of the map reduce job.

O/P:
6

stop-all.sh to stop the nodes 
